{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Copy of 1st DNN.ipynb","version":"0.3.2","provenance":[{"file_id":"1dfGGwB2_8F_pI7-viAFucRBAoPF-OQTP","timestamp":1539447420316},{"file_id":"1_UZit0JSpUSywCuQGJfX-SSinlb_x7jS","timestamp":1539442109468},{"file_id":"1gZYwZdkgXBJRr624SqWJ9f452BmKNkNT","timestamp":1539439432910},{"file_id":"1JURGwe4e5Z7928Zv2eiJVPCQNc702huM","timestamp":1521864568638}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"aNyZv-Ec52ot","colab_type":"text"},"cell_type":"markdown","source":["# **Import Libraries and modules**"]},{"metadata":{"id":"3m3w1Cw49Zkt","colab_type":"code","colab":{}},"cell_type":"code","source":["# https://keras.io/\n","!pip install -q keras\n","import keras"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Eso6UHE080D4","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten, Add\n","from keras.layers import Convolution2D, MaxPooling2D ,BatchNormalization\n","from keras.utils import np_utils\n","\n","from keras.datasets import mnist"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zByEi95J86RD","colab_type":"text"},"cell_type":"markdown","source":["### Load pre-shuffled MNIST data into train and test sets"]},{"metadata":{"id":"7eRM0QWN83PV","colab_type":"code","colab":{}},"cell_type":"code","source":["(X_train, y_train), (X_test, y_test) = mnist.load_data()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4a4Be72j8-ZC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":299},"outputId":"03e8f3a3-ab11-44bc-f69c-a2dc71d2965d","executionInfo":{"status":"ok","timestamp":1539448664643,"user_tz":-330,"elapsed":984,"user":{"displayName":"Raajesh Laguduva Rameshbabu","photoUrl":"","userId":"08877500412315789486"}}},"cell_type":"code","source":["print (X_train.shape)\n","from matplotlib import pyplot as plt\n","%matplotlib inline\n","plt.imshow(X_train[0])"],"execution_count":18,"outputs":[{"output_type":"stream","text":["(60000, 28, 28)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f54a7471a58>"]},"metadata":{"tags":[]},"execution_count":18},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<matplotlib.figure.Figure at 0x7f5513a9c390>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"dkmprriw9AnZ","colab_type":"code","colab":{}},"cell_type":"code","source":["X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n","X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"X2m4YS4E9CRh","colab_type":"code","colab":{}},"cell_type":"code","source":["X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","X_train /= 255\n","X_test /= 255"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0Mn0vAYD9DvB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"947ee687-9989-4155-a2f1-56bb0934e800","executionInfo":{"status":"ok","timestamp":1539448676330,"user_tz":-330,"elapsed":1035,"user":{"displayName":"Raajesh Laguduva Rameshbabu","photoUrl":"","userId":"08877500412315789486"}}},"cell_type":"code","source":["y_train[:10]"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"]},"metadata":{"tags":[]},"execution_count":21}]},{"metadata":{"id":"ZG8JiXR39FHC","colab_type":"code","colab":{}},"cell_type":"code","source":["# Convert 1-dimensional class arrays to 10-dimensional class matrices\n","Y_train = np_utils.to_categorical(y_train, 10)\n","Y_test = np_utils.to_categorical(y_test, 10)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fYlFRvKS9HMB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"outputId":"88fa2d5a-e64d-4b02-85eb-fa7ec2a3aaa4","executionInfo":{"status":"ok","timestamp":1539448682662,"user_tz":-330,"elapsed":895,"user":{"displayName":"Raajesh Laguduva Rameshbabu","photoUrl":"","userId":"08877500412315789486"}}},"cell_type":"code","source":["Y_train[:10]\n"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n","       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n","       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n","       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n","       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":23}]},{"metadata":{"id":"osKqT73Q9JJB","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.layers import Activation\n","model = Sequential()\n","\n"," \n","model.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(28,28,1)))\n","model.add(BatchNormalization(name='norm_1'))\n","model.add(Convolution2D(10, (1,1), activation='relu',))\n","\n","model.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(28,28,1)))\n","model.add(BatchNormalization(name='norm_2'))\n","model.add(Convolution2D(10, (1,1), activation='relu',))\n","\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","model.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(28,28,1)))\n","model.add(BatchNormalization(name='norm_3'))\n","model.add(Convolution2D(10, (1,1), activation='relu',))\n","\n","model.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(28,28,1)))\n","model.add(BatchNormalization(name='norm_4'))\n","model.add(Convolution2D(10, (1,1), activation='relu',))\n","\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","model.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(28,28,1)))\n","model.add(BatchNormalization(name='norm_5'))\n","model.add(Convolution2D(10, (1,1), activation='relu',))\n","\n","model.add(Convolution2D(10, 1, activation='relu'))\n","\n","model.add(Flatten())\n","model.add(Dense(10,activation='softmax'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TzdAYg1k9K7Z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":816},"outputId":"7d56e35a-df71-4ca4-d790-2d54b9e6d295","executionInfo":{"status":"ok","timestamp":1539448699081,"user_tz":-330,"elapsed":921,"user":{"displayName":"Raajesh Laguduva Rameshbabu","photoUrl":"","userId":"08877500412315789486"}}},"cell_type":"code","source":["model.summary()"],"execution_count":25,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_12 (Conv2D)           (None, 26, 26, 32)        320       \n","_________________________________________________________________\n","norm_1 (BatchNormalization)  (None, 26, 26, 32)        128       \n","_________________________________________________________________\n","conv2d_13 (Conv2D)           (None, 26, 26, 10)        330       \n","_________________________________________________________________\n","conv2d_14 (Conv2D)           (None, 24, 24, 32)        2912      \n","_________________________________________________________________\n","norm_2 (BatchNormalization)  (None, 24, 24, 32)        128       \n","_________________________________________________________________\n","conv2d_15 (Conv2D)           (None, 24, 24, 10)        330       \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 12, 12, 10)        0         \n","_________________________________________________________________\n","conv2d_16 (Conv2D)           (None, 10, 10, 32)        2912      \n","_________________________________________________________________\n","norm_3 (BatchNormalization)  (None, 10, 10, 32)        128       \n","_________________________________________________________________\n","conv2d_17 (Conv2D)           (None, 10, 10, 10)        330       \n","_________________________________________________________________\n","conv2d_18 (Conv2D)           (None, 8, 8, 32)          2912      \n","_________________________________________________________________\n","norm_4 (BatchNormalization)  (None, 8, 8, 32)          128       \n","_________________________________________________________________\n","conv2d_19 (Conv2D)           (None, 8, 8, 10)          330       \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 4, 4, 10)          0         \n","_________________________________________________________________\n","conv2d_20 (Conv2D)           (None, 2, 2, 32)          2912      \n","_________________________________________________________________\n","norm_5 (BatchNormalization)  (None, 2, 2, 32)          128       \n","_________________________________________________________________\n","conv2d_21 (Conv2D)           (None, 2, 2, 10)          330       \n","_________________________________________________________________\n","conv2d_22 (Conv2D)           (None, 2, 2, 10)          110       \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 40)                0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 10)                410       \n","=================================================================\n","Total params: 14,778\n","Trainable params: 14,458\n","Non-trainable params: 320\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"Zp6SuGrL9M3h","colab_type":"code","colab":{}},"cell_type":"code","source":["model.compile(loss='categorical_crossentropy',\n","             optimizer='adam',\n","             metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4xWoKhPY9Of5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":935},"outputId":"bcf24157-2de4-40cf-c42d-e44964654ba6","executionInfo":{"status":"ok","timestamp":1539449896181,"user_tz":-330,"elapsed":1189474,"user":{"displayName":"Raajesh Laguduva Rameshbabu","photoUrl":"","userId":"08877500412315789486"}}},"cell_type":"code","source":["model.fit(X_train, Y_train, batch_size=32, nb_epoch=25, verbose=1,validation_data=(X_test, Y_test))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n","  warnings.warn('The `nb_epoch` argument in `fit` '\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/25\n","60000/60000 [==============================] - 50s 835us/step - loss: 0.2826 - acc: 0.9115 - val_loss: 0.0780 - val_acc: 0.9742\n","Epoch 2/25\n","60000/60000 [==============================] - 48s 808us/step - loss: 0.0767 - acc: 0.9760 - val_loss: 0.0600 - val_acc: 0.9808\n","Epoch 3/25\n","60000/60000 [==============================] - 48s 808us/step - loss: 0.0586 - acc: 0.9818 - val_loss: 0.0481 - val_acc: 0.9856\n","Epoch 4/25\n","60000/60000 [==============================] - 48s 808us/step - loss: 0.0502 - acc: 0.9843 - val_loss: 0.0525 - val_acc: 0.9835\n","Epoch 5/25\n","60000/60000 [==============================] - 48s 807us/step - loss: 0.0441 - acc: 0.9862 - val_loss: 0.0515 - val_acc: 0.9838\n","Epoch 6/25\n","60000/60000 [==============================] - 48s 807us/step - loss: 0.0384 - acc: 0.9873 - val_loss: 0.0476 - val_acc: 0.9853\n","Epoch 7/25\n","60000/60000 [==============================] - 49s 816us/step - loss: 0.0336 - acc: 0.9889 - val_loss: 0.0744 - val_acc: 0.9791\n","Epoch 8/25\n","60000/60000 [==============================] - 49s 810us/step - loss: 0.0336 - acc: 0.9895 - val_loss: 0.0325 - val_acc: 0.9899\n","Epoch 9/25\n","60000/60000 [==============================] - 48s 802us/step - loss: 0.0288 - acc: 0.9911 - val_loss: 0.0334 - val_acc: 0.9889\n","Epoch 10/25\n","60000/60000 [==============================] - 48s 795us/step - loss: 0.0261 - acc: 0.9915 - val_loss: 0.0339 - val_acc: 0.9896\n","Epoch 11/25\n","60000/60000 [==============================] - 47s 787us/step - loss: 0.0253 - acc: 0.9917 - val_loss: 0.0453 - val_acc: 0.9854\n","Epoch 12/25\n","60000/60000 [==============================] - 47s 783us/step - loss: 0.0239 - acc: 0.9920 - val_loss: 0.0376 - val_acc: 0.9894\n","Epoch 13/25\n","60000/60000 [==============================] - 47s 785us/step - loss: 0.0243 - acc: 0.9923 - val_loss: 0.0339 - val_acc: 0.9899\n","Epoch 14/25\n","60000/60000 [==============================] - 47s 784us/step - loss: 0.0197 - acc: 0.9938 - val_loss: 0.0347 - val_acc: 0.9895\n","Epoch 15/25\n","60000/60000 [==============================] - 47s 780us/step - loss: 0.0210 - acc: 0.9932 - val_loss: 0.0358 - val_acc: 0.9896\n","Epoch 16/25\n","60000/60000 [==============================] - 47s 778us/step - loss: 0.0187 - acc: 0.9939 - val_loss: 0.0321 - val_acc: 0.9905\n","Epoch 17/25\n","60000/60000 [==============================] - 46s 775us/step - loss: 0.0179 - acc: 0.9939 - val_loss: 0.0303 - val_acc: 0.9908\n","Epoch 18/25\n","60000/60000 [==============================] - 46s 775us/step - loss: 0.0171 - acc: 0.9943 - val_loss: 0.0344 - val_acc: 0.9888\n","Epoch 19/25\n","60000/60000 [==============================] - 47s 776us/step - loss: 0.0167 - acc: 0.9948 - val_loss: 0.0332 - val_acc: 0.9900\n","Epoch 20/25\n","60000/60000 [==============================] - 46s 774us/step - loss: 0.0145 - acc: 0.9953 - val_loss: 0.0336 - val_acc: 0.9901\n","Epoch 21/25\n","60000/60000 [==============================] - 47s 782us/step - loss: 0.0160 - acc: 0.9947 - val_loss: 0.0339 - val_acc: 0.9904\n","Epoch 22/25\n","60000/60000 [==============================] - 47s 776us/step - loss: 0.0161 - acc: 0.9948 - val_loss: 0.0400 - val_acc: 0.9890\n","Epoch 23/25\n","60000/60000 [==============================] - 46s 773us/step - loss: 0.0127 - acc: 0.9956 - val_loss: 0.0398 - val_acc: 0.9880\n","Epoch 24/25\n","60000/60000 [==============================] - 46s 773us/step - loss: 0.0126 - acc: 0.9957 - val_loss: 0.0421 - val_acc: 0.9881\n","Epoch 25/25\n","60000/60000 [==============================] - 46s 775us/step - loss: 0.0138 - acc: 0.9955 - val_loss: 0.0298 - val_acc: 0.9920\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f54a75cfc88>"]},"metadata":{"tags":[]},"execution_count":27}]},{"metadata":{"id":"AtsH-lLk-eLb","colab_type":"code","colab":{}},"cell_type":"code","source":["score = model.evaluate(X_test, Y_test, verbose=0)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mkX8JMv79q9r","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b65003c4-b2da-4512-f417-e7cdc1430083","executionInfo":{"status":"ok","timestamp":1539449912592,"user_tz":-330,"elapsed":1140,"user":{"displayName":"Raajesh Laguduva Rameshbabu","photoUrl":"","userId":"08877500412315789486"}}},"cell_type":"code","source":["print(score)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["[0.02976246628436347, 0.992]\n"],"name":"stdout"}]},{"metadata":{"id":"OCWoJkwE9suh","colab_type":"code","colab":{}},"cell_type":"code","source":["y_pred = model.predict(X_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ym7iCFBm9uBs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":340},"outputId":"8dafecc4-fdb9-467e-cb03-148038359c35","executionInfo":{"status":"ok","timestamp":1539449920883,"user_tz":-330,"elapsed":1082,"user":{"displayName":"Raajesh Laguduva Rameshbabu","photoUrl":"","userId":"08877500412315789486"}}},"cell_type":"code","source":["print(y_pred[:9])\n","print(y_test[:9])"],"execution_count":31,"outputs":[{"output_type":"stream","text":["[[2.4377326e-13 4.4750395e-09 4.6362900e-11 8.9053120e-10 3.5669531e-10\n","  2.4214270e-08 3.1189212e-19 9.9999988e-01 2.7192504e-12 1.0291943e-07]\n"," [5.5721966e-07 6.7803842e-07 9.9999762e-01 2.6737031e-12 3.9384482e-10\n","  1.9456113e-08 7.0278475e-07 5.0145206e-07 1.7121982e-08 1.2869716e-08]\n"," [2.8546691e-14 9.9999952e-01 8.4881179e-08 1.2448692e-10 1.2833512e-08\n","  1.6261099e-07 1.5773735e-10 5.8015663e-09 4.4860917e-11 7.8232013e-08]\n"," [9.9999845e-01 2.4027986e-09 2.4083116e-07 8.3526480e-10 1.8386388e-09\n","  1.0719496e-08 8.9188433e-07 2.4187794e-11 2.3545252e-07 1.2116936e-07]\n"," [3.4001389e-11 5.6930483e-09 1.1137919e-09 4.7844673e-15 9.9997926e-01\n","  5.4205662e-09 6.0612463e-13 3.9263531e-10 1.1303918e-08 2.0770469e-05]\n"," [1.3045803e-12 9.9999917e-01 3.2621895e-08 2.5680036e-13 6.0421058e-08\n","  3.0355203e-08 6.7648269e-11 5.0089886e-07 1.9485276e-10 1.9909186e-07]\n"," [3.8711459e-14 3.1770372e-07 4.9070241e-08 2.2962407e-13 9.9245089e-01\n","  1.3814043e-05 7.4202667e-12 5.2380710e-06 8.5510510e-06 7.5211334e-03]\n"," [1.4460708e-10 2.4312214e-08 9.4302903e-09 2.7585412e-12 1.4811812e-04\n","  1.0812994e-08 4.5351977e-14 2.5422560e-09 1.0939337e-10 9.9985182e-01]\n"," [9.3682596e-05 9.4947921e-13 3.1138242e-07 8.2339440e-08 1.5104405e-08\n","  9.9221647e-01 7.6680509e-03 5.5264163e-08 1.8084222e-05 3.3604711e-06]]\n","[7 2 1 0 4 1 4 9 5]\n"],"name":"stdout"}]},{"metadata":{"id":"CT--y98_dr2T","colab_type":"code","colab":{}},"cell_type":"code","source":["layer_dict = dict([(layer.name, layer) for layer in model.layers])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2GY4Upv4dsUR","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","from matplotlib import pyplot as plt\n","from keras import backend as K\n","%matplotlib inline\n","# util function to convert a tensor into a valid image\n","def deprocess_image(x):\n","    # normalize tensor: center on 0., ensure std is 0.1\n","    x -= x.mean()\n","    x /= (x.std() + 1e-5)\n","    x *= 0.1\n","\n","    # clip to [0, 1]\n","    x += 0.5\n","    x = np.clip(x, 0, 1)\n","\n","    # convert to RGB array\n","    x *= 255\n","    #x = x.transpose((1, 2, 0))\n","    x = np.clip(x, 0, 255).astype('uint8')\n","    return x\n","\n","def vis_img_in_filter(img = np.array(X_train[2]).reshape((1, 28, 28, 1)).astype(np.float64), \n","                      layer_name = 'conv2d_14'):\n","    layer_output = layer_dict[layer_name].output\n","    img_ascs = list()\n","    for filter_index in range(layer_output.shape[3]):\n","        # build a loss function that maximizes the activation\n","        # of the nth filter of the layer considered\n","        loss = K.mean(layer_output[:, :, :, filter_index])\n","\n","        # compute the gradient of the input picture wrt this loss\n","        grads = K.gradients(loss, model.input)[0]\n","\n","        # normalization trick: we normalize the gradient\n","        grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n","\n","        # this function returns the loss and grads given the input picture\n","        iterate = K.function([model.input], [loss, grads])\n","\n","        # step size for gradient ascent\n","        step = 5.\n","\n","        img_asc = np.array(img)\n","        # run gradient ascent for 20 steps\n","        for i in range(20):\n","            loss_value, grads_value = iterate([img_asc])\n","            img_asc += grads_value * step\n","\n","        img_asc = img_asc[0]\n","        img_ascs.append(deprocess_image(img_asc).reshape((28, 28)))\n","        \n","    if layer_output.shape[3] >= 35:\n","        plot_x, plot_y = 6, 6\n","    elif layer_output.shape[3] >= 23:\n","        plot_x, plot_y = 4, 6\n","    elif layer_output.shape[3] >= 11:\n","        plot_x, plot_y = 2, 6\n","    else:\n","        plot_x, plot_y = 1, 2\n","    fig, ax = plt.subplots(plot_x, plot_y, figsize = (12, 12))\n","    ax[0, 0].imshow(img.reshape((28, 28)), cmap = 'gray')\n","    ax[0, 0].set_title('Input image')\n","    fig.suptitle('Input image and %s filters' % (layer_name,))\n","    fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])\n","    for (x, y) in [(i, j) for i in range(plot_x) for j in range(plot_y)]:\n","        if x == 0 and y == 0:\n","            continue\n","        ax[x, y].imshow(img_ascs[x * plot_y + y - 1], cmap = 'gray')\n","        ax[x, y].set_title('filter %d' % (x * plot_y + y - 1))\n","\n","vis_img_in_filter()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9tvptcn8dxvp","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}